version: '3.8'

services:
  # Main FastAPI Application
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: it_ticket_analyzer_api
    ports:
      - "8000:8000"
    environment:
      - DEBUG=false
      - HOST=0.0.0.0
      - PORT=8000
      - WEAVIATE_HOST=http://weaviate:8080
      - OLLAMA_HOST=http://ollama:11434
      - USE_OLLAMA=true
      - USE_HUGGINGFACE=true
      - LOG_LEVEL=INFO
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      - weaviate
      - redis
      - ollama
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Weaviate Vector Database
  weaviate:
    image: semitechnologies/weaviate:1.22.4
    container_name: weaviate_db
    ports:
      - "8080:8080"
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH='/var/lib/weaviate'
      - DEFAULT_VECTORIZER_MODULE=none
      - ENABLE_MODULES=text2vec-openai,text2vec-huggingface,qna-openai
      - CLUSTER_HOSTNAME=node1
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Ollama for Local LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama_server
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    networks:
      - it_analyzer_network
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Redis for Caching
  redis:
    image: redis:7-alpine
    container_name: redis_cache
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - it_analyzer_network
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru

  # PostgreSQL (Optional - for persistent storage)
  postgres:
    image: postgres:15-alpine
    container_name: postgres_db
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=it_ticket_analyzer
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres123
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Nginx Reverse Proxy (Optional)
  nginx:
    image: nginx:alpine
    container_name: nginx_proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Monitoring with Grafana (Optional)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana_monitoring
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Prometheus for Metrics (Optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus_metrics
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Celery Worker for Background Tasks (Optional)
  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_worker
    command: celery -A main.celery worker --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      - redis
      - api
    restart: unless-stopped
    networks:
      - it_analyzer_network

  # Celery Beat for Scheduled Tasks (Optional)
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_beat
    command: celery -A main.celery beat --loglevel=info
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      - redis
      - api
    restart: unless-stopped
    networks:
      - it_analyzer_network

volumes:
  weaviate_data:
    driver: local
  ollama_data:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local
  grafana_data:
    driver: local
  prometheus_data:
    driver: local

networks:
  it_analyzer_network:
    driver: bridge