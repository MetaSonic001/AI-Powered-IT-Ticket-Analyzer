# AI-Powered IT Ticket Analyzer & Auto-Suggester

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-supported-blue.svg)](https://www.docker.com/)

Enterprise-grade AI-powered system for automated IT ticket analysis, classification, priority prediction, and solution recommendation using multi-agent architecture.

## ğŸŒŸ Features

- **ğŸ¤– Multi-Agent AI System**: Using CrewAI for specialized ticket analysis agents
- **ğŸ“Š Multiple LLM Support**: Ollama, Hugging Face, Groq, Gemini with automatic fallbacks
- **ğŸ” Vector Search**: Weaviate-powered knowledge base with semantic search
- **ğŸ“ˆ Real-time Analytics**: Comprehensive dashboard with ticket trends and insights  
- **ğŸ”§ Auto-Classification**: Smart categorization of IT tickets into predefined categories
- **âš¡ Priority Prediction**: Intelligent priority assignment with resolution time estimates
- **ğŸ’¡ Solution Recommendations**: RAG-powered solution suggestions from knowledge base
- **ğŸ“š Knowledge Management**: Automated ingestion from multiple data sources
- **ğŸŒ RESTful API**: Complete FastAPI-based REST API with async support
- **ğŸ³ Docker Ready**: Full containerization with docker-compose setup

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API   â”‚    â”‚  Multi-Agent    â”‚    â”‚  Knowledge Base â”‚
â”‚                 â”‚â”€â”€â”€â”€â”‚   CrewAI        â”‚â”€â”€â”€â”€â”‚   (Weaviate)    â”‚
â”‚  - REST Endpointsâ”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  - Async Supportâ”‚    â”‚ - Classifier    â”‚    â”‚ - Vector Search â”‚
â”‚  - Validation   â”‚    â”‚ - Prioritizer   â”‚    â”‚ - Semantic RAG  â”‚
â”‚  - Analytics    â”‚    â”‚ - Recommender   â”‚    â”‚ - Auto-indexing â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Model Service  â”‚
                    â”‚                 â”‚
                    â”‚ - Ollama        â”‚
                    â”‚ - Hugging Face  â”‚
                    â”‚ - Groq/Gemini   â”‚
                    â”‚ - Auto-fallback â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd it-ticket-analyzer
   ```

2. **Setup environment**
   ```bash
   python scripts/setup.py
   ```

3. **Start with Docker**
   ```bash
   docker-compose up -d
   ```

4. **Access the API**
   - API Documentation: http://localhost:8000/api/docs
   - Weaviate Console: http://localhost:8080
   - Grafana Dashboard: http://localhost:3000

### Option 2: Local Development

1. **Prerequisites**
   - Python 3.11+
   - Ollama (optional but recommended)
   - Weaviate instance (or use Docker)

2. **Setup**
   ```bash
   # Run setup script
   python scripts/setup.py
   
   # Install dependencies
   pip install -r requirements.txt
   
   # Initialize system
   python scripts/initialize.py
   
   # Start development server
   ./scripts/run_dev.sh
   ```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file (automatically generated by setup script):

```env
# Model Configuration
USE_OLLAMA=true
OLLAMA_HOST=http://localhost:11434
USE_HUGGINGFACE=true
HUGGINGFACE_TOKEN=your_token_here

# External APIs (optional)
GROQ_API_KEY=your_groq_key
GEMINI_API_KEY=your_gemini_key

# Vector Database
WEAVIATE_HOST=http://localhost:8080

# Data Sources
KAGGLE_USERNAME=your_kaggle_username
KAGGLE_KEY=your_kaggle_key
```

### Ollama Models

The system uses these Ollama models (automatically pulled):
- `nomic-embed-text:latest` - For embeddings
- `gemma2:2b` - For text generation and classification

## ğŸ“‹ API Endpoints

### Core Ticket Analysis
- `POST /api/v1/tickets/analyze` - Complete ticket analysis
- `POST /api/v1/tickets/classify` - Classification only
- `POST /api/v1/tickets/predict-priority` - Priority prediction
- `POST /api/v1/tickets/bulk-process` - Batch processing

### Knowledge Management
- `POST /api/v1/solutions/recommend` - Get solution recommendations
- `GET /api/v1/solutions/search` - Search knowledge base
- `POST /api/v1/knowledge/ingest` - Ingest new knowledge

### Analytics & Monitoring
- `GET /api/v1/analytics/dashboard` - Dashboard data
- `GET /api/v1/analytics/reports` - Generate reports
- `GET /api/v1/health` - Health check
- `GET /api/v1/models/status` - Model status

## ğŸ’¡ Usage Examples

### Analyze a Ticket

```python
import httpx

ticket_data = {
    "title": "Cannot connect to WiFi network",
    "description": "User reports being unable to connect to corporate WiFi. Getting authentication error.",
    "requester_info": {
        "name": "John Doe",
        "department": "Sales",
        "location": "New York Office"
    }
}

response = httpx.post("http://localhost:8000/api/v1/tickets/analyze", json=ticket_data)
analysis = response.json()

print(f"Category: {analysis['classification']['category']}")
print(f"Priority: {analysis['priority_prediction']['priority']}")
print(f"Solutions: {len(analysis['recommended_solutions'])}")
```

### Get Solution Recommendations

```python
response = httpx.post("http://localhost:8000/api/v1/solutions/recommend", json={
    "query": "email synchronization issues mobile device",
    "category": "Email Issues",
    "max_results": 5
})

recommendations = response.json()
for solution in recommendations['recommendations']:
    print(f"- {solution['title']} (Score: {solution['similarity_score']:.2f})")
```

## ğŸ“Š Data Sources

The system automatically ingests data from:

- **Kaggle Datasets**: IT helpdesk and support ticket datasets
- **Synthetic Data**: Generated realistic IT support scenarios  
- **Web Scraping**: Technical documentation and knowledge articles
- **Manual Input**: Custom knowledge base entries

## ğŸ¤– Multi-Agent Architecture

### Specialized Agents

1. **Ticket Classifier Agent**
   - Categorizes tickets into predefined categories
   - Identifies subcategories and technical domains
   - Provides confidence scores and reasoning

2. **Priority Predictor Agent**
   - Assesses business impact and urgency
   - Estimates resolution timeframes
   - Considers user context and historical patterns

3. **Solution Recommender Agent**
   - Searches knowledge base for relevant solutions
   - Provides step-by-step troubleshooting guides
   - Ranks solutions by relevance and effectiveness

4. **Quality Assurance Agent**
   - Reviews and validates analysis results
   - Ensures completeness and accuracy
   - Provides quality metrics

## ğŸ“ˆ Analytics & Reporting

### Dashboard Metrics
- Total tickets analyzed
- Average processing time
- Classification accuracy
- Knowledge base size
- Category distribution
- Priority trends

### Available Reports
- Summary reports with key metrics
- Category analysis with deep insights  
- Trend analysis over time periods
- Performance analytics

## ğŸ” Advanced Features

### RAG (Retrieval-Augmented Generation)
- Semantic search using Weaviate vector database
- Context-aware solution recommendations
- Knowledge base auto-expansion

### Model Flexibility  
- Multiple LLM providers with automatic fallbacks
- Local and cloud-based model support
- Performance optimization for different use cases

### Scalability
- Async FastAPI with high concurrency
- Containerized architecture  
- Horizontal scaling support
- Caching and optimization

## ğŸ§ª Testing

Run the test suite to verify installation:

```bash
python scripts/test_installation.py
```

## ğŸ“š Documentation

- **API Documentation**: Available at `/api/docs` when server is running
- **Model Documentation**: See `docs/models.md`
- **Deployment Guide**: See `docs/deployment.md`
- **Configuration Reference**: See `docs/configuration.md`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™‹ Support

- **Issues**: GitHub Issues for bug reports and feature requests
- **Documentation**: Comprehensive docs in `/docs` directory
- **Examples**: Sample code in `/examples` directory

## ğŸ¯ Roadmap

- [ ] Mobile app support
- [ ] Advanced ML model fine-tuning
- [ ] Integration with popular ITSM tools
- [ ] Advanced analytics with ML insights
- [ ] Multi-language support
- [ ] Voice-to-ticket conversion

---

**Built with â¤ï¸ using FastAPI, CrewAI, Weaviate, and modern AI/ML technologies**
