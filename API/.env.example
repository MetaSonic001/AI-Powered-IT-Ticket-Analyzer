# Example .env for API (copy to .env and edit values)

# ========== Common (Docker or Local) ==========
# Server
DEBUG=false
HOST=0.0.0.0
PORT=8000

# Model Configuration
# LLM Provider Configuration (enable only what you have API keys for)
# If a provider is disabled (false) or has no API key, it will be skipped in the fallback chain

# Groq (Primary - Fast and cost-effective)
# Set USE_GROQ=false to disable, even if you have an API key
USE_GROQ=true
GROQ_API_KEY=

# Gemini (Optional - Google's model for complex analysis)
# Set USE_GEMINI=true and provide API key to enable
USE_GEMINI=false
GEMINI_API_KEY=

# Ollama (Optional - Local models for privacy)
# Set USE_OLLAMA=true if you have Ollama installed locally
USE_OLLAMA=false
OLLAMA_HOST=http://localhost:11434

# Hugging Face (for embeddings and fallback)
# Recommended to keep enabled for embeddings
USE_HUGGINGFACE=true
HUGGINGFACE_TOKEN=

# FALLBACK CHAIN BEHAVIOR:
# The system will try providers in this order (only if enabled):
# 1. Groq (if USE_GROQ=true and GROQ_API_KEY is set)
# 2. Gemini (if USE_GEMINI=true and GEMINI_API_KEY is set)
# 3. Ollama (if USE_OLLAMA=true)
# 4. HuggingFace (if USE_HUGGINGFACE=true)
#
# Example configurations:
# - Groq only: USE_GROQ=true, USE_GEMINI=false, USE_OLLAMA=false
# - Groq + Gemini fallback: USE_GROQ=true, USE_GEMINI=true, USE_OLLAMA=false
# - Local only: USE_GROQ=false, USE_GEMINI=false, USE_OLLAMA=true

# Directories
DATA_DIR=./data
MODELS_DIR=./models
LOGS_DIR=./logs

# Logging
LOG_LEVEL=INFO

# CrewAI
CREW_VERBOSE=true
CREW_MEMORY=true

# Performance
MAX_CONCURRENT_REQUESTS=5
BATCH_SIZE=32
ENABLE_CACHING=true
CACHE_TTL=3600


# ========== Docker-only ==========
# Set to true when running via docker-compose
USE_DOCKER=false
# In Docker, the Weaviate service is reachable at http://weaviate:8080
#WEAVIATE_HOST=http://weaviate:8080
WEAVIATE_API_KEY=
WEAVIATE_CLASS=ITKnowledge


# ========== Local-only (no Docker) ==========
# Keep USE_DOCKER=false for local mode
# Local vector DB (persistent): ChromaDB
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Optional: general app persistence (non-vector)
USE_SQLITE=true
SQLITE_DB_PATH=./data/app.db
LEDGER_DB_PATH=./data/ledger.db

# If you run a local Weaviate (instead of Chroma) outside Docker, point to localhost
#WEAVIATE_HOST=http://localhost:8080


# Data Sources (optional)
KAGGLE_USERNAME=
KAGGLE_KEY=
GITHUB_TOKEN=
